01.08.2020

Reread the MSc Project Guidance Document (https://moodle.city.ac.uk/mod/resource/view.php?id=1484635) and a project report given as sample reference (Minah 2015 - https://moodle.city.ac.uk/mod/resource/view.php?id=1484742)

Examined audi dataset preview from https://www.a2d2.audi/a2d2/en/download.html trying to work out how to map images to steering angles. Have been in touch with Dr. Mahmud, on the the authors of Audi papers with respect to aforementioned mapping.

Managed ok. Timestamp is in TIA format. For every .png image there is a corresponding .json file with image timestamp information. All steering angles are provided in a single file containing bus signals, such that the reading taken at the time nearest to a given image may be considered the desired steering angle. A few random images were examined, consisting of urban scenes and not adequate as the vehicle is driving through a city circuit, where no inferences are made about vision, road geometry and steering.

03.08.2020

Downloading Ford Dataset - need to unpack and look at rosbag data to infer steering angles (algorithm to be written). 
Amazon mechanical turk taps into this data, to find rainy sections.
See https://avdata.ford.com/downloads/default.aspx

Structuring report Introduction and Objective based on Chammas 2019, using wordcounts and reference counts as a base.

We need to make a start asap on the Unity testing circuits (x3), that will effectively generate our data. We also need to make a start asap on the NVIDIA vanilla model, be it in PyTorch or Keras/Tensorflow, and get training and testing this model while we develop the alternative models.

Good-to-have would be an AWS training/testing instance, depending on costs.

04.08.2020

Replied to email from supervisor, suggesting a write-up be made of preliminary results, which may be re-used in report (thesis). I'll aim to get that over by end of August. A lot to do i.e. create tracks, create models generate data (see next entry).

Watched Tawn Kramer's intro video to Unity x Tensorflow self driving setup. Model trained on 100 GB of data - https://www.youtube.com/watch?v=e0AFMilaeMI

Flow chart, diagram generating software. I am looking, considering Gimp, Inkscape. Also found Dia, which looks promissing.

25.08.2020

** Ran on both camber and devcloud:

To generate models.

1. clone git repo:

$ git clone https://github.com/dsikar/sdsandbox.git

2. Copy data

$ scp devcloud:~/git/sdsandbox/dataset/autogen_track.tar.gz

3. Unpack data to ~/git/sdsandbox/dataset/log

4. Change directory to src and run

$ python train.py --model=../outputs/camber_model_4.h5

Notes:

Camber fails with error "Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled"

** Our main task w.r.t. models is adapt additional models (i.e. in addition to NVIDIA model) to become regression models, as the non-NVIDIA architectures are defined as classification models where the last layer will tipically be a 1000-way output (with softmax?) drawing the "winner" from a distribution (discuss).

We found this article lathuilire2018comprehensive (added to dissertation.bib) with a discussion about deep regression models.

28/29.08.202

** Still ruminating over GoogleLeNet article. Pressing issue now is get models trained and tested on basic setup, i.e., Unity 3D generated images and steering angles. we have a head start in Tawn Kraemer's code (train.py) and other implementations.  

The link trail:

One Udacity alumni:
https://towardsdatascience.com/deep-learning-for-self-driving-cars-7f198ef4cfa2
did a good write-up, reported problems and cites this repo as the salvation:
https://github.com/hminle/car-behavioral-cloning-with-pytorch/
who in turn was inspired by this repo:
https://github.com/naokishibuya/car-behavioral-cloning
Naoki did a good write-up here:
https://medium.com/@naokishibuya/introduction-to-udacity-self-driving-car-simulator-4d78198d301d

Tasks (one of two, better the two, but at least one):
1. Get the unity 3D data we have to work with naoki's model - medium difficulty
2. Get Naoki's model to work with Tawn's setup - better but potentially hard, as a large library needs to travel across.
https://github.com/tawnkramer/sdsandbox
Let's start with 1. ... 21:26...

We need to check if image sizes are compatible, or what kind of adjustment needs to be made...

Later, need to assess what is the minimum steering angle required, and the quantisation, i.e. precision. Currently angle tipically is 0.09035701304674149

Tawn Kraemer angle in radians	Angle in degrees
0.09035701304674149		5.1770754969996453099

If we use 0.09, we get 5.15662, which is pretty dawn close.
If we use 0.1, we get 5.72958. Which is not ideal but gives
us an idea of what we could do with binning these values.

We will need to look at angle values as a whole, to decide. 
The hypothesis is that angles will not vary a hell of a lot.

Naoki's model seems to spend most of the time between +- 2 degrees.
going as far as +-8 degrees, with two decimal placess, so about 1600
discrete values, though that could probably be reduced a lot, if say
we allow changes in 1/3 of a degree, that would be 48 values total,
with the majority around 12 values (4 * 3 ~ +- 2).

So basically we would be looking at converting and truncating, i.e.
convert 0.09035701304674149 to 5.1770754969996453099 and
truncate 5.17, or round, TBD.

And jumping ahead, here is a tutorial on adding rain to Unity 3D through "particles"

https://www.youtube.com/watch?v=Ax3WNI-3C60

Another good one, maybe better - simpler, parts 1 and 2
https://www.youtube.com/watch?v=VN6RzRQ-SWU
https://www.youtube.com/watch?v=8inqJf4aNH0

Some pointers
https://www.youtube.com/watch?v=YHHVCqoNuEY

29/30/31.08.2020

We looked at Andrew Ng's videos on ConvNets and also read and annotated the GoogleLeNet (Inception) paper. 

We now have under 3 months to deliver first draft and under 4 months to deliver dissertation. We need to start thinking about downsizing project if we do not get some results by the end of this month, e.g. one or two nets only, no evaluation on circuit, just on steering angles.

01.09.2020

We looked at the VGG paper and wrote some notes.

06.09.2020

We tried to install tensorflow and keras on RPI zero W without success, so trying to compile from source. Also tried on Ubuntu 16.04 without success, both procedures as outlines in:

https://www.tensorflow.org/lite/guide/build_rpi

Notes on the AWS Ubuntu build. We had to allocate extra space to the volume (up from 8 to 20GB) then on the instance (t2.micro):

   42  lsblk
   43  sudo growpart /dev/xvda 1
   44  lsblk
   45  df -h
   46  sudo resize2fs /dev/xvda1
   47  df -h

We used a docker container:

   22  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
   23  sudo apt-key fingerprint 0EBFCD88
   24  sudo add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   25     $(lsb_release -cs) \
   26     stable"
   27  sudo apt-get update
   28  sudo apt-get install docker-ce docker-ce-cli containerd.io
   29  apt-cache madison docker-ce
   30  sudo docker run hello-world
   31  sudo systemctl status docker
   32  sudo usermod -aG docker ubuntu

Downloaded the recommended image:

   50  docker pull tensorflow/tensorflow:latest-devel

then ran docker:

   57  docker run -it tensorflow/tensorflow:latest-devel

We tried to cross-compile in the docker image (is this the right jargon) and ran into problems.

NB to exit docker:

$ exit

To get shell of running container:

$ docker exec -it <mycontainer> bash

To list images:

$ docker images

To list running images:

$ docker ps -a

To commit:

$ docker commit <image id> name (I think)

To kill a running image:

$ docker kill <image id>

Some online notes on docker:

https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04

Wrt cross-compiling tensorflow lite, this link looks promissing:
https://www.tensorflow.org/install/source_rpi#python-3.7

Started running on EC2 instance but ran out of space, having already increased volume size under 6 hours ago so fell foul of AWS rules and had to halt for the night.

Need now, once more space is allocated, rerun from tensorflow_src directory:

$ tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/tools/ci_build/pi/build_raspberry_pi.sh PI_ONE

Also, this linked page:
https://www.tensorflow.org/install/pip

Had a wheel I don't think I've tried, so maybe tomorrow:

Raspberry PI (CPU-only)
Python 3, Pi0 or Pi1	https://storage.googleapis.com/tensorflow/raspberrypi/tensorflow-2.3.0-cp35-none-linux_armv6l.whl

07.09.2020

Trying again to build a tensorflow wheel for RPI Zero. Running t3.medium (4GB memory) with 40GB.

Installed as previous log entry, starting with:

$ sudo apt-get update
$ sudo apt-get install build-essential

Then docker as per notes, then cloned tensorflow into tensorflow_src, and from that directory ran:

$ sudo tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
> tensorflow/tools/ci_build/pi/build_raspberry_pi.sh PI_ONE

Previous install from this morning got stuck and bricked instance, so starting again. Failing this, we will look at building a Ubuntu 16.04 cross compiler box tomorrow and taking it from there.

Added a virtual environment to the pi zero as per:
https://www.tensorflow.org/install/pip#raspberry-pi

Note, when finished:

(venv) $ deactivate  # don't exit until you're done using TensorFlow

Inside the virtual environment we then ran:

wget https://github.com/lhelontra/tensorflow-on-arm/releases/download/v2.2.0/tensorflow-2.2.0-cp37-none-linux_armv6l.whl

And then

$ pip install tensorflow-2.2.0-cp37-none-linux_armv6l.whl

That installed tensorflow ok, keras also in, (about 12 hours' work), though both are very slow. TODO read Adrian Rosenbrook's notes on increasing virtual memory or something like that. We are stopping the ubuntu build but might still be worth pursuing tensorflow lite build for inference only.

TODO Run tensorflow lite inference to see if it flies. DONE! Inference ran ok on raspberry pi zero w. Need to document plus address previous TODO.

08.09.2020

Failed build on Ubuntu 18.04 tensorflow branch 2.3 and master:

1. build-essential
2. Installed docker
3. Cloned tensorflow
4. Ran sudo tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/tools/ci_build/pi/build_raspberry_pi.sh PI_ONE

** Tried to build tensorflow lite...

https://www.tensorflow.org/lite/guide/build_rpi

Failed. As things stand, we were unable to cross compile on 1. AWS, 2. 16 core, 32 GB memory Ubuntu 18.04 and natively on RPI Zero. TODO try with Ubuntu 16.04 as this is referenced in the docs.

Looks like we will not be able to run tensorflow lite on pi zero:

There are some examples on tensorflow website for (presumed) desktop:

# loading 
https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python
# running
https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi

12.09.2020

Big TODO left from this week, NEED to document tensorflow running on pi zero w.

Tasks for the day:

1. Read up on the donkey car simulator (Tawn Kramer) as documented on Donkey Car:
http://docs.donkeycar.com/guide/simulator/

2. Look at building a dev machine on AWS. NB We have a physical machine (Ubuntu 18.04) but could do with a cloud version for agility.

3. Read up on Amazon SageMaker group truth w.r.t. labelling rainy/dry images from self-driving datasets.

Week beginning 14.09.2020

1. Looks into ROS (robot operating system) and unpacking steering angles from Udacity dataset

2. Look at implementing Clear Grasp algorithm - unrelated to dissertation but some overlap with ROS which may be synergetic.


